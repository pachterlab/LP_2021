<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Text mining LCM transcriptomics abstracts | Museum of Spatial Transcriptomics</title>
<meta name="author" content="Lambda Moses">
<meta name="author" content="Lior Pachter">
<meta name="description" content='To analyze trends in LCM followed by microarray or RNA-seq, abstracts were downloaded from the PubMed API, with search term "((laser capture microdissection) OR (laser microdissection)) AND...'>
<meta name="generator" content="bookdown 0.39 with bs4_book()">
<meta property="og:title" content="Chapter 6 Text mining LCM transcriptomics abstracts | Museum of Spatial Transcriptomics">
<meta property="og:type" content="book">
<meta property="og:description" content='To analyze trends in LCM followed by microarray or RNA-seq, abstracts were downloaded from the PubMed API, with search term "((laser capture microdissection) OR (laser microdissection)) AND...'>
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Text mining LCM transcriptomics abstracts | Museum of Spatial Transcriptomics">
<meta name="twitter:description" content='To analyze trends in LCM followed by microarray or RNA-seq, abstracts were downloaded from the PubMed API, with search term "((laser capture microdissection) OR (laser microdissection)) AND...'>
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.7.0/transition.js"></script><script src="libs/bs3compat-0.7.0/tabs.js"></script><script src="libs/bs3compat-0.7.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Museum of Spatial Transcriptomics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introduction</a></li>
<li class="book-part">Prequel era</li>
<li><a class="" href="prequel.html"><span class="header-section-number">2</span> Prequel era</a></li>
<li><a class="" href="prequel-analysis.html"><span class="header-section-number">3</span> Data analysis in the prequel era</a></li>
<li class="book-part">Current era</li>
<li><a class="" href="current.html"><span class="header-section-number">4</span> From the past to the present</a></li>
<li><a class="" href="current-techs.html"><span class="header-section-number">5</span> Current era technologies</a></li>
<li><a class="active" href="text-mining.html"><span class="header-section-number">6</span> Text mining LCM transcriptomics abstracts</a></li>
<li><a class="" href="current-analysis.html"><span class="header-section-number">7</span> Data analysis in the current era</a></li>
<li class="book-part">Future perspectives</li>
<li><a class="" href="future.html"><span class="header-section-number">8</span> From the past to the present to the future</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pachterlab/LP_2021">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="text-mining" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Text mining LCM transcriptomics abstracts<a class="anchor" aria-label="anchor" href="#text-mining"><i class="fas fa-link"></i></a>
</h1>
<p>To analyze trends in LCM followed by microarray or RNA-seq, abstracts were downloaded from the PubMed API, with search term <code>"((laser capture microdissection) OR (laser microdissection)) AND ((microarray) OR (transcriptome) OR (RNA-seq))"</code>. For preprints, abstracts from the search term “laser microdissection” were downloaded from bioRxiv. Because bioRiv’s advanced search does not acknowledge parentheses, a more complicated search term was not used. Upon random inspection, the retrieved abstracts mostly seem relevant. The number of LCM transcriptomics search results dwarfs the number of publications for other methods of spatial transcriptomics and seems to show two peaks, one around 2012, and the other in 2020 and 2021 (Figure <a href="text-mining.html#fig:lcm-year">6.1</a>); the LCM corpus contains 2252 abstracts as of March 26, 2021, while there are between 500 and 600 papers in the curated database.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lcm-year"></span>
<img src="06-text-mining_files/figure-html/lcm-year-1.png" alt="Number of publications in LCM transcriptomics PubMed search results over time. Bin width is 365 days." width="672"><p class="caption">
Figure 6.1: Number of publications in LCM transcriptomics PubMed search results over time. Bin width is 365 days.
</p>
</div>
<p>LCM transcriptomics is also more geographically diffuse and spread out into many less well-known institutions and some developing countries, though some elite institutions are among the top contributors, such as Harvard Medical School and Massachusetts General Hospital (Boston), Columbia University, NYU, Rockefeller, and Sloan-Kettering (New York), NIH (Bethesda), and Cambridge University (Cambridge, UK) (Figure <a href="text-mining.html#fig:lcm-map">6.2</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lcm-map"></span>
<img src="06-text-mining_files/figure-html/lcm-map-1.png" alt="Geographic distribution of LCM transcriptomics research, with top 10 cities labeled. Number of publications is binned over longitude and latitude." width="100%"><p class="caption">
Figure 6.2: Geographic distribution of LCM transcriptomics research, with top 10 cities labeled. Number of publications is binned over longitude and latitude.
</p>
</div>
<p>After identifying common and relevant phrases in the abstracts, the abstracts were tokenized into unigrams. We used the <code>stm</code> R package <span class="citation">(<a href="references.html#ref-Roberts2019">M. E. Roberts, Stewart, and Tingley 2019</a>)</span> to identify topics. The cities in which the research was conducted, date published or posted on bioRxiv (linear, not transformed), and journal (including bioRxiv) were used as covariates for topic prevalence, because labs and journals may have preferred topics and city is a proxy to institution, and it’s reasonable to assume that prevalence of at least some topic changes through time, such as due to evolution of technology. Cities and journals with fewer than 5 papers were lumped into “Other”. From a trade off between held out likelihood and residual, and between topic exclusivity and semantic coherence, we chose 50 topics. Code used to find this can be found <a href="https://github.com/pachterlab/museumst/blob/master/data-raw/lcm_text_mining.Rmd">here</a>.</p>
<p>Here <code>stm</code> stands for structural text mining. A generative model of word counts is fitted with the word counts in each abstract as well as abstract level covariates, here date, city, and journal. Among parameters of the model estimated are the proportion of each topic in each abstract after accounting for covariates (<span class="math inline">\(\theta\)</span>), topic proportions in the corpus (<span class="math inline">\(\gamma\)</span>), and probability of getting each word from each topic (<span class="math inline">\(\beta\)</span>). See the <a href="https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf"><code>stm</code> vignette</a> for more details. <code>stm</code> can not only detect topics without having a human read all the abstracts, but also find how covariates relate to topic prevalence.</p>
<div id="topic-model" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Topic modeling<a class="anchor" aria-label="anchor" href="#topic-model"><i class="fas fa-link"></i></a>
</h2>
<p>As already mentioned, microarray was first demonstrated on LCM samples in 1999, profiling 477 cDNAs from rat neurons <span class="citation">(<a href="references.html#ref-Luo1999">Luo et al. 1999</a>)</span>. Since then, LCM transcriptomics has been used on many research topics, such as various aspects of cancer (topics 5, 6, 8, 10, 11, 13, 16, 20, 24, 27, 34, 44, 50), botany (topics 9, 15, 21, 40, 43, 45), developmental biology (topics 1, 3, 17, 18, 29, 35, 39), neuroscience (topics 7, 14, 19, 23, 25, 32, 33, 36, 47), immunology (topic 12, 22, 48), miRNA (topic 5), and technical issues related to LCM (topics 4, 28, 37, 41) (Figure <a href="text-mining.html#fig:topics">6.3</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topics"></span>
<img src="06-text-mining_files/figure-html/topics-1.png" alt="Top words for each of the 50 topics, ordered by expected topic prevalence and showing top 5 words contributing to each topic." width="100%"><p class="caption">
Figure 6.3: Top words for each of the 50 topics, ordered by expected topic prevalence and showing top 5 words contributing to each topic.
</p>
</div>
In most cases, the top 5 words in each topic give us a decent idea what the topic is about. We can also plot the probability to get top words (<span class="math inline">\(\beta\)</span>) in each topic.
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-words"></span>
<img src="06-text-mining_files/figure-html/topic-words-1.png" alt="Probability of top 10 words in each topic. Open image in new tab to see the text." width="100%"><p class="caption">
Figure 6.4: Probability of top 10 words in each topic. Open image in new tab to see the text.
</p>
</div>
<p>While in most cases, the topic is apparent from the top words, some topics are less apparent (e.g. topic 49). From the top words and quick glances of abstracts with the highest proportion of each topic, the 50 topics are summarized here in more human readable terms:</p>
<ol style="list-style-type: decimal">
<li>Stem cell and fetal development</li>
<li>GWAS, genetic screens, and genetics of complex phenotypes</li>
<li>Biomechanics, ECM, eye lens, muscles, and morphogenesis</li>
<li>Data analysis, especially of RNA-seq, but also of 3D genome structure and microarray</li>
<li>miRNAs in cancer</li>
<li>Quantitative analyses of cancer, clinical and bioinformatic</li>
<li>Hippocampus and Alzheimer’s disease, sometimes related to Down syndrome</li>
<li>Prostate cancer and other stuff in molecular biology and biochemistry, probably because some prostate cancer papers have an emphasis on molecular biology</li>
<li>Plant embryos, plant development, and some stuff about evolution and ecology related to plants</li>
<li>Proteomics, especially in cancer</li>
<li>Cancer progression and diagnostics, especially lung cancer</li>
<li>Inflammation and immunology, especially in skin diseases</li>
<li>Breast cancer and liver cancer, with an emphasis in data analysis</li>
<li>Neural circuitry, neural plasticity, brain injury, and behavior</li>
<li>Plant gamitogenesis and reproduction</li>
<li>Spasmolytic polypeptide-expressing metaplasia (SPEM), oncogenes, KRAS</li>
<li>Endometrium and implantation. Somehow the top 2 entries are about hearing loss. Why? Epithelium?</li>
<li>Cell cycle, also hepatic zonation and circadian rhythm (the latter is also a cycle)</li>
<li>Neurons, especially dopaminergic</li>
<li>Tumor stroma and microenvironment</li>
<li>Plant roots</li>
<li>Intestine, especially microbiome and immune response</li>
<li>Hypothalamus, obesity, and appetite</li>
<li>PDAC, and some stuff about glioma and prostate cancer</li>
<li>ALS, and other neurodegenerative diseases affecting motor neurons</li>
<li>Epigenetics</li>
<li>Tumor single cell profiling and cellular heterogeneity</li>
<li>Tissue isolation and preparation</li>
<li>Bone growth plate, especially recovery after radiotherapy, and some other stuff like oocytes, glaucoma, and epithelial injury</li>
<li>Pancreas and diabetes, especially T2D</li>
<li>Lymphocytes, lymphatic and blood vessels</li>
<li>Prefrontal cortex and schizophrenia</li>
<li>Synapses, dendritic spines, neuron potentiation, sometimes related to memory</li>
<li>Cancer genomics, mutations, and phylogeny</li>
<li>Bone formation, but also some other stuff about cancer and kidneys</li>
<li>Neurodegenerative diseases, Alzheimer’s, Parkinson’s, and multiple system atrophy</li>
<li>Spatial single cell techniques and imaging</li>
<li>Connective tissues and ECM, and some other stuff about circadian rhythms</li>
<li>Stem cells and development</li>
<li>Plant seed development and reproduction</li>
<li>RNA extraction and amplification, especially in microarray, but also in RNA-seq</li>
<li>Lots of different stuff about epithelium</li>
<li>Plant leaves, but also other stuff about gamitogenesis</li>
<li>Cancer pathway analyses and molecular and cellular mechanisms</li>
<li>Plant nitrogen fixation and soil microbiome</li>
<li>Lots of different stuff related to fibrosis and fibroblasts, such as in lung diseases and graft rejection</li>
<li>Neuron morphogenesis, axon guidance, somehow also angiogenesis, protein signaling</li>
<li>Inflammation, immune response, especially in atherosclerosis, though there’s some other stuff about blood vessels</li>
<li>Model organisms and in vitro model systems</li>
<li>Intrahepatic cholangiocarcinoma (ICC)</li>
</ol>
<p>Some of them might not really be related to LCM (e.g. GWAS), and some seem to be a mixture of different topics recognized by humans but seemingly united by something else in common. There are very likely more than 50 topics present, depending on how a topic is defined. The topics can be broadly categorized into Botany, Cancer, Development, Immunology, Neuroscience, Technical, and Other, though these categories can overlap. Some of the “Other” topics seem like mixtures of multiple topics, such as topic 29, while some are very specific and relevant, such as topic 30 (pancreas and diabetes). The broad categories will be used in further analyses.</p>
<p>Clusters of related topics can be seen in the topic correlation plot. See <a href="https://rdrr.io/cran/stm/man/topicCorr.html">documentation of <code>topicCorr</code> in the <code>stm</code> package</a> for more details. Here we use a high-dimensional undirected graphical (HUGE) model <span class="citation">(<a href="references.html#ref-Zhao2012">T. Zhao et al. 2012</a>)</span> to estimate the topic correlation graph. The topic proportions (<span class="math inline">\(\theta\)</span>) are assumed to be multivariate Gaussian, and HUGE tries to identify edges connecting topics that are not independent from each other conditioned on everything else, while trying to keep the graph sparse (few edges). While <span class="math inline">\(\theta\)</span> is not Gaussian, the results from HUGE aren’t unreasonable.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-corr"></span>
<img src="06-text-mining_files/figure-html/topic-corr-1.png" alt="Correlation between topics." width="100%"><p class="caption">
Figure 6.5: Correlation between topics.
</p>
</div>
<p>Indeed, cancer, botany, neuroscience, and technical topics tend to cluster together, although this is not the case for immunology and development.</p>
</div>
<div id="word-time" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Changes of word usage through time<a class="anchor" aria-label="anchor" href="#word-time"><i class="fas fa-link"></i></a>
</h2>
<p>We binned dates into years and tested for association of word proportion in each year with the year by fitting a logistic regression model and checking significance of the coefficient for year; word frequency per year since 2001 for the significant words (after Benjamini-Hochberg multiple testing correction) are shown in Figure <a href="text-mining.html#fig:wbt">6.6</a>. Because too many words are significant, only top 10 from words with decreasing frequency and top 10 with increasing frequency are plotted.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:wbt"></span>
<img src="06-text-mining_files/figure-html/wbt-1.png" alt="Word frequency over time since 2001 for words significantly associated with time, sorted from the most decreasing to the most increasing in frequency in time according to the slope in the model. The adjusted p-value of each word is shown. Vertical line marks June 6, 2008, when the first paper about RNA-seq was published (Nagalakshmi et al. 2008)." width="100%"><p class="caption">
Figure 6.6: Word frequency over time since 2001 for words significantly associated with time, sorted from the most decreasing to the most increasing in frequency in time according to the slope in the model. The adjusted p-value of each word is shown. Vertical line marks June 6, 2008, when the first paper about RNA-seq was published <span class="citation">(<a href="references.html#ref-Nagalakshmi2008">Nagalakshmi et al. 2008</a>)</span>.
</p>
</div>
<p>Here we see that words and phrases associated with microarray and RNA amplification have declined in frequency, while words associated with RNA-seq, single cell, as well as words discussing molecular mechanisms have increased in frequency (Figure <a href="text-mining.html#fig:wbt">6.6</a>). While transcripts from LCM samples from recent studies were still amplified, the relevant terms decreased in frequency probably because more recent studies, such as ones in the curated database, tend to cite established protocols and kits of library preparation that do the amplification such as Smart-seq2 rather than discussing amplification directly. The “spatial” is associated with current era techniques. Such trends can also be clustered and shown in a heatmap.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:word-heat"></span>
<img src="06-text-mining_files/figure-html/word-heat-1.png" alt="Heat map clustering changes in word frequency over time. The rows of the matrix are normalized, only showing trend rather than frequency." width="100%"><p class="caption">
Figure 6.7: Heat map clustering changes in word frequency over time. The rows of the matrix are normalized, only showing trend rather than frequency.
</p>
</div>
<p>Some words have increased in frequency, especially since 2015 (Figure <a href="text-mining.html#fig:word-heat">6.7</a>). Some words sharply decreased in frequency in the early 2000s. However, some words have increased in frequency, peaking in the late 2000s and early 2010s, before declining. Among the terms whose frequency peaked around the early 2010s are “microarray” and “microarray analysis”, perhaps because while RNA-seq was introduced in 2008, microarray did not immediately become obsolete, or perhaps because microarray results are often compared to RNA-seq results, though perhaps wordings changed through the 2000s so the “cDNA” in “cDNA microarray” was omitted (Figure <a href="text-mining.html#fig:wbt">6.6</a>). Frequency of “real time PCR” also declined, probably because real time PCR was often performed along side microarray but not scRNA-seq to corroborate microarray results (e.g. <span class="citation">(<a href="references.html#ref-Cunnea2010">Cunnea et al. 2010</a>; <a href="references.html#ref-Kitamura2017">Kitamura et al. 2017</a>)</span>), so usage of this term declined with the decline of the cDNA microarray. Besides microarray related terms, some of the words that decreased in frequency are biological terms related to cancer. The “frequency” here is the proportion of all words from all abstracts of a year taken up by a word; the decline in proportion can either be due to decline in interest in the topics that use the word or growth in other topics that don’t use the word. This will be explored further in the next section.</p>
</div>
<div id="topic-time" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Changes of topic prevalence through time<a class="anchor" aria-label="anchor" href="#topic-time"><i class="fas fa-link"></i></a>
</h2>
<p>We tested for association of prevalence of each of the 50 topics with time using the <code>estimateEffect</code> function in the <code>stm</code> package. Samples of the parameters were taken from the variational posterior of the <code>stm</code> model to estimate the variances of the slopes of the linear model of topic prevalence vs. date published, as well as to test whether topic prevalence is significantly associated with time. The p-values of the slopes were corrected for multiple hypothesis testing with the Benjamini-Hochberg method. While the linear model only captures monotonous changes, a more flexible model, such as b-spline transform of the date, was not used because of the modest size of this corpus – on average, each topic has only 45 abstracts, though some topics are larger and some smaller.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-trends"></span>
<img src="06-text-mining_files/figure-html/topic-trends-1.png" alt="Topic prevalence over time since 2001 with fitted linear model. Gray ribbon indicates 95% confidence interval (CI) of the slope, estimated from the samples of the variational posterior of the stm model. Vertical line indicates advent of RNA-seq in 2008. Light blue facet strip means decreasing trend with adjusted p &lt; 0.05, and pink strip means increasing." width="100%"><p class="caption">
Figure 6.8: Topic prevalence over time since 2001 with fitted linear model. Gray ribbon indicates 95% confidence interval (CI) of the slope, estimated from the samples of the variational posterior of the <code>stm</code> model. Vertical line indicates advent of RNA-seq in 2008. Light blue facet strip means decreasing trend with adjusted p &lt; 0.05, and pink strip means increasing.
</p>
</div>
<p>As many topics have statistically significant associations with time, only the top 10 most decreasing and top 10 most decreasing topics are plotted here (that’s what I intended, but there were only 8 significantly decreasing topics, so top 12 increasing topics are shown). In the early 2000s, a major topic of research about LCM was reliability of T7-based PCR amplification of the small amount of transcripts from samples for microarray, but the prevalence of this topic (topic 41) has declined over time (Figure <a href="text-mining.html#fig:wbt">6.6</a>, Figure <a href="text-mining.html#fig:topic-trends">6.8</a>). The reason for such decline can be a combination of the following: First, other topics in neuroscience and botany emerged and grew (Figure <a href="text-mining.html#fig:topic-trends">6.8</a>); some of them are now among the most prevalent topics (Figure <a href="text-mining.html#fig:topics">6.3</a>). Second, usage of terms related to microarray and RNA amplification for microarray declined while usage of terms related to RNA-seq increased after 2008 due to the advent of RNA-seq because the latter replaced microarray as the transcriptomics method of choice, so the decline is expected (Figure <a href="text-mining.html#fig:wbt">6.6</a>). Also as expected, prevalence of topics in data analysis (topic 4) and spatial single cell and imaging technologies (topic 37) increased. Interestingly, cancer topics are among the most significantly decreasing (Figure <a href="text-mining.html#fig:word-heat">6.7</a>, Figure <a href="text-mining.html#fig:topic-trends">6.8</a>). Because unlike cDNA microarray, these topics are still relevant today, such decline is puzzling.</p>
<p>Next, we checked whether whether the rise of topics not directly related to cancer may be relevant to the decline of proportions of cancer topics. In <code>stm</code>, the abstracts are not hard assigned to topics. Rather, each abstract has a proportion of each topic, and abstracts often have over 90% of one topic. Here, for simplicity, we say an abstract “has” a topic if the proportion of the topic in the abstract is at least 25%.</p>
(ref:topic-count-cap) Number of abstracts with each topic whose proportions changed the most in time. Gray ribbon is the 95% CI of the line fitted to the count per year.
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-count"></span>
<img src="06-text-mining_files/figure-html/topic-count-1.png" alt="(ref:topic-count-cap)" width="100%"><p class="caption">
Figure 6.9: (ref:topic-count-cap)
</p>
</div>
<p>When the number of abstracts with each topic is plotted, the declines are less drastic or reversed while the increases became much more drastic, especially after 2015, perhaps due to the rise of scRNA-seq, whose library preparation methods made it possible to quantify transcripts from small amount of tissues from LCM (Figure <a href="text-mining.html#fig:topic-count">6.9</a>). These trends don’t necessarily correspond to the overall trend across the corpus (Figure <a href="text-mining.html#fig:lcm-year">6.1</a>). Then we see in recent years a diversification of topics that may be related to LCM from search results, resulting into decrease of proportion of some older topics the interest in which might not have drastically decreased if not somewhat increased, though not increasing as quickly as other topics. Nevertheless, it is clear that some cancer topics have decreased even in counts. However, remember that some of the <code>stm</code> topics seem to be mixtures of multiple topics recognizable by humans and these <code>stm</code> topics might have picked up aspects of the abstracts less readily noticed by humans. In other words, it might not be that interest in some cancers decreased per se, but thanks to scRNA-seq, the way these cancers are discussed changed, using words that contributed to other, growing topics. Furthermore, because so many different topics are drastically growing in recent years, the increase in proportion of each of them became less drastic.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-corr-trend"></span>
<img src="06-text-mining_files/figure-html/topic-corr-trend-1.png" alt="Correlation between topics colored by both broad categories of the topics and whether its proportion increased, decreased, or did not significantly change (n.s.)." width="100%"><p class="caption">
Figure 6.10: Correlation between topics colored by both broad categories of the topics and whether its proportion increased, decreased, or did not significantly change (n.s.).
</p>
</div>
<p>Now return to the topic correlation graph, and all the 50 topics, along with their trends, are shown (Figure <a href="text-mining.html#fig:topic-corr-trend">6.10</a>). Overall, cancer topics tend to be decreasing in proportion. As already seen in Figure <a href="text-mining.html#fig:topic-count">6.9</a>, this is in part due to growth in non-cancer topics but in part due to decline in some cancer topics. Botany and neuroscience topics tend to increase in proportion. This trend is also evident in the topic correlations. Microarray and RNA amplification (topic 41) is correlated with a cancer topic, while spatial single cell and imaging (topic 37) and data analysis (topic 4) are correlated with neuroscience topics. Topic 27, which is about single cell profiling of tumors, has grown, perhaps due to the growth of scRNA-seq. Possibly, as cancer is still relevant, the decline in some cancer topics fed into topic 27 as tumors are examined at the single cell level.</p>
</div>
<div id="topic-city" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Association of topics with city<a class="anchor" aria-label="anchor" href="#topic-city"><i class="fas fa-link"></i></a>
</h2>
<p>Again, with the <code>estimateEffects</code> function, we identify cities associated with certain topics. Some topics might be more spread out, while some some may be confined to a few institutions, which are approximated by city here because it’s more difficult to automatically extract institutions from the author address on PubMed than cities. Some institutions might specialize in certain topics. Also note that while for PubMed papers, the cities of the first author are used, because the first author has greater contribution to the paper, only the address of the corresponding author is available from the bioRxiv API. Furthermore, multiple institutions across continents may collaborate on one paper, so the cities here only give a rough idea where LCM related research takes place. Here only the names of the cities are used, with the state and country they are in to distinguish between cities with the same name, without the longitude and latitude, because we don’t expect an association between topic and the coordinates in and of themselves, nor do we expect spatial autocorrelation of the topics.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:topic-loc"></span>
<img src="06-text-mining_files/figure-html/topic-loc-1.png" alt="Cities associated with topics (p &lt; 0.005) shown on a map." width="100%"><p class="caption">
Figure 6.11: Cities associated with topics (p &lt; 0.005) shown on a map.
</p>
</div>
<p>Here we note that Center for Dementia Research, Nathan Kline Institute in Orangeburg has greatly contributed to research in hippocampal CA1 pyramidal neurons in Alzheimer’s disease and Down syndrome (topic 7) (Figure <a href="text-mining.html#fig:topic-loc">6.11</a>). This is the first time I heard of Nathan Kline. Department of Plant Biology at Cornell, Ithaca has greatly contributed to study of plant development (topic 9). Topic 17 is a mixture of topics recognizable by humans; besides the endometrium, some of the top entries are about hearing loss, which come from University of Rochester. George Mason University in Manassas, Virginia contributed several papers about cancer pathway analysis (topic 44). University of Pittsburgh has disproportionate contribution to the study of prefrontal cortex and schizophrenia (topic 32), dating back to 2007. Centro de Biotecnologia y Genomica de Plantas (UPM-INIA), Madrid has disproportionate contribution to the study of soil microbiome and nitrogen fixation (topic 45). University of Sheffield has a long history and disproportionate contribution to the study of neurodegenerative diseases affecting motor neurons (topic 25), dating back to 2007.</p>
<p>Association of a topic with an institution that used to greatly contribute to the topic but then stopped might also explain why some topics declined in prevalence over time although drastic growth in other topics might be a better explanation (Figure <a href="text-mining.html#fig:topic-trends">6.8</a>, <a href="text-mining.html#fig:topic-count">6.9</a>). Topic 29 prominently features the bone growth plate though this <code>stm</code> topic has entries for other biological systems as well. These bone growth plate papers come from Upstate Medical University in Syracuse, New York, from 2005 to 2010. Decline in topic 29 might be related to cessation of study of the growth plate at this institution after 2010, though other institutions have not picked up this topic afterwards. Institute of Human Genetics and Anthropology, Friedrich-Schiller-University in Jena, Germany greatly contributed to cancer proteomics (topic 10) between 2004 and 2011 but then stopped, though other institutions carried on studying this topic. Kyushu University Beppu Hospital in Japan greatly contributed to quantitative analyses in cancer (topic 6) from 2005 to 2014, although other institutions continue contributing to this topic, whose paper count actually increased over time although the topic’s proportion decreased due to drastic growth in other topics (<a href="text-mining.html#fig:topic-count">6.9</a>). The vast majority of LCM related publications from Sendai, Japan are about breast cancer (topic 13), from between 2007 to 2017, which is why Sendai is associated with this city although this topic is widespread.</p>
<p>Association of a city with a topic can also be visualized with topic proportion in each city from <code>estimateEffect</code> (Figure <a href="text-mining.html#fig:city-pe">6.12</a>). Here topic 45 (soil microbiome and nitrogen fixation) is plotted, but readers on RStudio Cloud can try other topics.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:city-pe"></span>
<img src="06-text-mining_files/figure-html/city-pe-1.png" alt="Proportion of topic 45 in each city. Error bars are 95% CI of the point estimate." width="576"><p class="caption">
Figure 6.12: Proportion of topic 45 in each city. Error bars are 95% CI of the point estimate.
</p>
</div>
<p>Here “disproportionate” means disproportionate within this corpus of LCM related search results. Institutions with “disproportionate” contribution to a topic do not necessarily dominate such topic although the topic may dominate the institution, i.e. the topic takes up a very large proportion of abstracts from this institution within this corpus. Nor are these institutions necessarily elite; this analysis might be an interesting way to discover labs from not so well-known institutions that may be outstanding in some topics. The institutions are often not elite because elite institutions often greatly contribute to many topics, weakening the association of the institution to the topic. Except for growth plate in Syracuse, we have not identified topics largely confined to an institution.</p>
</div>
<div id="glove" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> GloVe word embedding<a class="anchor" aria-label="anchor" href="#glove"><i class="fas fa-link"></i></a>
</h2>
<p>We used global vector (GloVe) embedding to identify linear substructures in the word vector space of the LCM transcriptomics abstract corpus and to identify contexts <span class="citation">(<a href="references.html#ref-Pennington">Pennington, Socher, and Manning, n.d.</a>)</span>. In GloVe embedding, words are represented by vectors. Words with similar meanings tend to be closer together in this vector space, and differences between word vectors can encode meaning as well. The “meanings” come from the context, or word co-occurrence. GloVe was devised to find a word embedding with properties like “king” - “man” + “woman” = “queen” or “ice” - “solid” + “gas” = “steam”, and related words like “cancer” and “tumor” are close together but both are far from unrelated words like “flower”.</p>
<p>This corpus was used to train a 125 dimensional embedding, and the embeddings of words occurring more than 30 times in the corpus were projected to lower dimensions with principal component analysis (PCA) to find axes explaining the most variance in the embedding, hopefully identifying dominant axes of meaning within this corpus. The words are also Louvain clustered in the embedding space to find clusters of words related in meaning.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pca-elbow"></span>
<img src="06-text-mining_files/figure-html/pca-elbow-1.png" alt="Proportion of variance explained by each of the first 20 principal components (PC)." width="576"><p class="caption">
Figure 6.13: Proportion of variance explained by each of the first 20 principal components (PC).
</p>
</div>
<p>The first principal component (PC) explains over 5% of the variance, and then the “elbow” is at PC5.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pc12"></span>
<img src="06-text-mining_files/figure-html/pc12-1.png" alt="Projection of word embeddings into the first 2 PCs. Each point is a word occuring over 30 times in the corpus. Not all words are labeled to avoid overlaps in the labels. Words and points are colored by Louvain clusters." width="100%"><p class="caption">
Figure 6.14: Projection of word embeddings into the first 2 PCs. Each point is a word occuring over 30 times in the corpus. Not all words are labeled to avoid overlaps in the labels. Words and points are colored by Louvain clusters.
</p>
</div>
<p>Words more positive in PC1 are often gene names, parts of gene names, or acronyms, and names of specific biological entities or processes. In contrast, words more negative in PC1 tend to be more general and more widely used. PC2 separates the technical from the biological (Figure <a href="text-mining.html#fig:pc12">6.14</a>). As expected, “cancer”, “tumor”, and “disease” are not far from each other (bottom left), and “malignant” and “invasive” are close (bottom center). PC1 explains more variance than all other PCs; though it’s only 5.5%, it picked up a very important dimension in word meanings in this corpus. PCs are arranged in decreasing order of variance explained.</p>

<div class="rmdnote">
Note that when the PCA plot is made on different computers, the signs of PCs might flip, because the sign does not affect the magnitude of the eigenvalue (i.e. variance explained). PCs are eigenvectors of the covariance matrix of the GloVe dimensions; an eigenvector multiplied by a scalar is still an eigenvector with the same eigenvalue.
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pc34"></span>
<img src="06-text-mining_files/figure-html/pc34-1.png" alt="Projection of word embeddings into the 3rd and 4th PCs." width="100%"><p class="caption">
Figure 6.15: Projection of word embeddings into the 3rd and 4th PCs.
</p>
</div>
<p>PC3 separates processes and interactions from entities of samples, tissues, organs, and diseases. PC4 separates the molecular and cellular and the quantitative from the qualitative. Some of the qualitative terms are used to discuss implications of results of the papers (Figure <a href="text-mining.html#fig:pc34">6.15</a>).</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="current-techs.html"><span class="header-section-number">5</span> Current era technologies</a></div>
<div class="next"><a href="current-analysis.html"><span class="header-section-number">7</span> Data analysis in the current era</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#text-mining"><span class="header-section-number">6</span> Text mining LCM transcriptomics abstracts</a></li>
<li><a class="nav-link" href="#topic-model"><span class="header-section-number">6.1</span> Topic modeling</a></li>
<li><a class="nav-link" href="#word-time"><span class="header-section-number">6.2</span> Changes of word usage through time</a></li>
<li><a class="nav-link" href="#topic-time"><span class="header-section-number">6.3</span> Changes of topic prevalence through time</a></li>
<li><a class="nav-link" href="#topic-city"><span class="header-section-number">6.4</span> Association of topics with city</a></li>
<li><a class="nav-link" href="#glove"><span class="header-section-number">6.5</span> GloVe word embedding</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pachterlab/LP_2021/blob/main/supplement/06-text-mining.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pachterlab/LP_2021/edit/main/supplement/06-text-mining.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Museum of Spatial Transcriptomics</strong>" was written by Lambda Moses, Lior Pachter. It was last built on 2024-04-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
